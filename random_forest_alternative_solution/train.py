import time
from pathlib import Path
from typing import Union, List
import random
import hydra
import numpy as np
from sklearn.metrics import f1_score, accuracy_score
import os
import dgl
import wandb
import torch
from sklearn.ensemble import RandomForestClassifier
from omegaconf import DictConfig
from pathlib import Path
from pytorch_lightning import Trainer
from script.dataset import Dataset
from script.model import RandomForestModel
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
import dgl
import torch
import numpy as np
import pytorch_lightning as pl
import torch.nn.functional as F
import dgl.nn.pytorch as graph_nn
from torch import nn
from torch import nn
from dgl.nn import Sequential
from typing import Any, Optional, Tuple
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import StratifiedShuffleSplit


def get_layer(
        conv_algorithm: str,
        input_dimension: int,
        output_dimension: int
) -> nn.Module:
    support_algorithm = {
        "SAGEConv": graph_nn.SAGEConv(
            input_dimension,
            output_dimension,
            activation=F.relu,
            aggregator_type='mean',
            norm=F.normalize
        ),
        "GraphConv": graph_nn.GraphConv(
            input_dimension,
            output_dimension,
            activation=F.relu
        ),
        "GATConv": graph_nn.GATConv(
            input_dimension,
            output_dimension,
            activation=F.relu,
            num_heads=1
        )
    }
    conv_algorithm = conv_algorithm if conv_algorithm in support_algorithm.keys() else "GraphConv"
    return support_algorithm[conv_algorithm]


def get_model(
        input_dimension: int,
        conv_count=3,
        conv_algorithm='GraphConv'
):
    conv_dimensions = [64, 32, 16]
    conv_layers = []
    for layer in conv_dimensions[:conv_count]:
        conv_layers.append(get_layer(
            conv_algorithm,
            input_dimension,
            output_dimension=layer))
        input_dimension = layer
    conv_layers = Sequential(*conv_layers)
    return conv_layers


@hydra.main(config_path="config", config_name="config")
def train_model(cfg: DictConfig):
    dataset = Dataset(**cfg['dataset'])
    train_vector, train_label = dataset.train_dataset
    val_vector, val_label = dataset.val_dataset
    conv_layer = get_model(**cfg['model'])
    for epoch in range(100):
        for sample in train_vector:
            h = sample.ndata['features']
            h = conv_layer(sample, h)
            print(h)
    return None


if __name__ == '__main__':
    start_time = time.time()
    train_model()
    end_time = time.time()
