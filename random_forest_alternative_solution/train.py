import time
from pathlib import Path
from typing import Union, List
import random
import hydra
import numpy as np
from sklearn.metrics import f1_score, accuracy_score
import os
import dgl
import wandb
import torch
from sklearn.ensemble import RandomForestClassifier
from omegaconf import DictConfig
from script.dataset import Dataset
import dgl
import torch
import numpy as np
import pytorch_lightning as pl
import torch.nn.functional as F
import dgl.nn.pytorch as graph_nn
from torch import nn
from torch import nn
from dgl.nn import Sequential
from typing import Any, Optional, Tuple
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score


def get_layer(
        conv_algorithm: str,
        input_dimension: int,
        output_dimension: int
) -> nn.Module:
    support_algorithm = {
        "SAGEConv": graph_nn.SAGEConv(
            input_dimension,
            output_dimension,
            activation=F.relu,
            aggregator_type='mean',
            norm=F.normalize
        ),
        "GraphConv": graph_nn.GraphConv(
            input_dimension,
            output_dimension,
            activation=F.relu
        ),
        "GATConv": graph_nn.GATConv(
            input_dimension,
            output_dimension,
            activation=F.relu,
            num_heads=1
        )
    }
    conv_algorithm = conv_algorithm if conv_algorithm in support_algorithm.keys() else "GraphConv"
    return support_algorithm[conv_algorithm]


def get_model(
        input_dimension: int,
        conv_count=3,
        conv_algorithm='GraphConv'
):
    conv_dimensions = [64, 32, 16]
    conv_layers = []
    for layer in conv_dimensions[:conv_count]:
        conv_layers.append(get_layer(
            conv_algorithm,
            input_dimension,
            output_dimension=layer))
        input_dimension = layer
    conv_layers = Sequential(*conv_layers)
    return conv_layers


@hydra.main(config_path="config", config_name="config")
def train_model(cfg: DictConfig):
    dataset = Dataset(**cfg['dataset'])
    conv_layer = get_model(**cfg['model'])
    fc_layer = nn.Linear(16,1)
    rf_layer = RandomForestClassifier()
    
    for epoch in range(5):
        train_vector = []
        pred_vector = []
        train_graph, train_label, val_graph, val_label = dataset.get_shuffle()
        print(len(train_graph))
        for index, sample in enumerate(train_graph):
            # print(f"Proccesing epoch {epoch} sample {index}")
            h = sample.ndata['function_name']
            h = conv_layer(sample, h)
            hg = np.average(h.detach().numpy(),axis=0).tolist()
            train_vector.append(hg)
        
        rf_layer.fit(train_vector, train_label)

        for index, sample in enumerate(val_graph):
            # print(f"Prediction epoch {epoch} sample {index}")
            h = sample.ndata['function_name']
            h = conv_layer(sample, h)
            hg = np.average(h.detach().numpy(),axis=0).tolist()
            pred_vector.append(hg)
        predictions = rf_layer.predict(pred_vector)
        print('==========================')
        print(f'epoch {epoch}')
        print(accuracy_score(predictions,val_label))
        print(f1_score(predictions,val_label))
        print('==========================')
        
        
    return None


if __name__ == '__main__':
    start_time = time.time()
    train_model()
    end_time = time.time()
