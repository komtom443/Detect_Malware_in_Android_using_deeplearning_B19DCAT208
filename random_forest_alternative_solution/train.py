import time
from pathlib import Path
from typing import Union, List
import random
import hydra
import numpy as np
from sklearn.metrics import f1_score, accuracy_score
import os
import dgl
import wandb
import torch
from sklearn.ensemble import RandomForestClassifier
from omegaconf import DictConfig
from pathlib import Path
from pytorch_lightning import Trainer
from script.dataset import Dataset
from script.model import RandomForestModel
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
import dgl
import torch
import numpy as np
import pytorch_lightning as pl
import torch.nn.functional as F
import dgl.nn.pytorch as graph_nn
from torch import nn
from torch import nn
from dgl.nn import Sequential
from typing import Any, Optional, Tuple
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import StratifiedShuffleSplit

def get_layer(
        conv_algorithm: str,
        input_dimension: int,
        output_dimension: int
) -> nn.Module:
    support_algorithm = {
            "SAGEConv": graph_nn.SAGEConv(
                input_dimension,
                output_dimension,
                activation=F.relu,
                aggregator_type='mean',
                norm=F.normalize
            ),
            "GraphConv": graph_nn.GraphConv(
                input_dimension,
                output_dimension,
                activation=F.relu
            ),
            "GATConv": graph_nn.GATConv(
                input_dimension,
                output_dimension,
                activation=F.relu,
                num_heads=1
            )
        }
    conv_algorithm = conv_algorithm if conv_algorithm in support_algorithm.keys() else "GraphConv"
    return support_algorithm[conv_algorithm]

def get_model(
        input_dimension: int,
        conv_count = 3,
        conv_algorithm = 'GraphConv'
):
    conv_dimensions = [64, 32, 16]
    conv_layers = []
    for layer in conv_dimensions[:conv_count]:
        conv_layers.append(get_layer(
            conv_algorithm,
            input_dimension,
            output_dimension=layer))
        input_dimension = layer
    conv_layers = Sequential(*conv_layers)
    return conv_layers

def get_sample(path: Union[str, Path]):
    label = str(Path(path).stem).lower()
    graphs, _ = dgl.data.utils.load_graphs(str(path))
    graph: dgl.DGLGraph = dgl.add_self_loop(graphs[0])
    return [graph, label]


def load_dataset(
        paths: Union[str, Path],
        ratios: List[int] = [0.75, 0.25]):
    paths = Path(paths)
    if not paths.exists():
        raise FileNotFoundError(f"Thư mục {paths} không tồn tại!")
    
    paths = [get_sample(path) for path in paths.iterdir()]
    sss = StratifiedShuffleSplit(
        n_splits=1,
        test_size=ratios[0],
        random_state=0,
    )

    train_dataset, val_dataset = [[],[]],[[],[]]
    return train_dataset, val_dataset

@hydra.main(config_path="config", config_name="config")
def train_model(cfg: DictConfig):
    Dataset(**cfg['dataset'])
    # [train_vector, train_correct_label], [val_vector, val_correct_label] = load_dataset(**cfg['dataset'])
    return None

if __name__ == '__main__':
    start_time = time.time()
    train_model()
    end_time = time.time()