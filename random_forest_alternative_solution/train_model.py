import hydra
import numpy as np
from sklearn.metrics import f1_score, accuracy_score

import os
import dgl
import wandb
import torch
from sklearn.ensemble import RandomForestClassifier
from omegaconf import DictConfig
from pathlib import Path

from pytorch_lightning import Trainer
from script.model import RandomForestModel
from core.data_module import MalwareDataModule
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
from core.callbacks import InputMonitor, BestModelTagger, MetricsLogger

def get_samples(file_dir: str):
    file_dir = Path(file_dir)
    samples, labels = [], []
    graph_list = []
    for file in file_dir.iterdir():
        name = str(file.stem)
        graphs, _ = dgl.data.utils.load_graphs(str(file))
        graph: dgl.DGLGraph = dgl.add_self_loop(graphs[0])
        graph_list.append(graph_list)
        # graph.ndata['function_name'] = graph.ndata['function_name'].view(-1, 1)
        # print(name.lower(), 1 if 'benig' in name.lower() else 0)
        samples.append(np.average(graph.ndata['function_name'], axis=0))
        labels.append(1 if 'benig' in name.lower() else 0)
    return samples, labels, graph_list


@hydra.main(config_path="config", config_name="conf")
def train_model(cfg: DictConfig):
    print(cfg['model'])
    data_module = MalwareDataModule(**cfg['data'])

    model = RandomForestModel(**cfg['model'])

    callbacks = [ModelCheckpoint(
        dirpath=os.getcwd(),
        filename=str('{epoch:02d}-{val_accuracy:.2f}.pt'),
        monitor='val_accuracy',
        mode='min',
        save_last=True,
        save_top_k=-1
    )]

    trainer_kwargs = dict(cfg['trainer'])
    force_retrain = cfg.get('force_retrain', False)
    # if Path('last.ckpt').exists() and not force_retrain:
    #     trainer_kwargs['resume_from_checkpoint'] = 'last.ckpt'

    if 'logger' in cfg:
        # We use WandB logger
        logger = WandbLogger(
            **cfg['logger']['args'],
            tags=[f'testing' if "testing" in cfg else "training"]
        )
        if "testing" in cfg:
            logger.experiment.summary["test_type"] = cfg["testing"]
        logger.watch(model)
        logger.log_hyperparams(cfg['logger']['hparams'])
        if logger:
            trainer_kwargs['logger'] = logger
            callbacks.append(InputMonitor())
            # callbacks.append(BestModelTagger(monitor='val_loss', mode='min'))
            callbacks.append(MetricsLogger(stages='all'))

    trainer = Trainer(
        callbacks=callbacks,
        **trainer_kwargs
    )
    testing = cfg.get('testing', '')
    if not testing:
        trainer.fit(model, datamodule=data_module)
    else:
        if testing not in ['last', 'best'] and 'epoch' not in testing:
            raise ValueError(
                f"testing must be one of 'best' or 'last' or 'epoch=N'. It is {testing}")
        elif 'epoch' in testing:
            # epoch in testing
            epoch = testing.split('@')[1]
            checkpoints = list(Path(os.getcwd()).glob(f"epoch={epoch}*.ckpt"))
            if len(checkpoints) < 0:
                print(f"Checkpoint at epoch = {epoch} not found.")
            assert len(
                checkpoints) == 1, f"Multiple checkpoints corresponding to epoch = {epoch} found."
            ckpt_path = checkpoints[0]
        else:
            if not Path('last.ckpt').exists():
                raise FileNotFoundError(
                    "No last.ckpt exists. Could not do any testing.")
            if testing == 'last':
                ckpt_path = 'last.ckpt'
            else:
                # best
                last_checkpoint = torch.load('last.ckpt')
                ckpt_path = last_checkpoint['callbacks'][ModelCheckpoint]['best_model_path']
        print(f"Using checkpoint {ckpt_path} for testing.")
        model = RandomForestModel.load_from_checkpoint(ckpt_path, **cfg['model'])
        trainer.test(model, datamodule=data_module, verbose=True)
    wandb.finish()

    # train_sample, train_label, train_graph_list = get_samples(
    #     cfg['data']['train_dir'])
    # test_sample, test_label, _ = get_samples(cfg['data']['test_dir'])

    # train_feats = model(train_graph_list)
    # rf = RandomForestClassifier(n_estimators=int(cfg['trainer']['max_epochs']))
    # rf.fit(train_sample, train_label)

    # test_predictions = rf.predict(test_sample)
    # test_accuracy = accuracy_score(test_label, test_predictions)
    # test_f1_score = f1_score(test_label, test_predictions)

    # wandb.log({"test_accuracy": test_accuracy, "test_f1_score": test_f1_score})

    # wandb.sklearn.plot_classifier(
    #     rf, train_sample, test_sample, train_label, test_label)


if __name__ == '__main__':
    train_model()
