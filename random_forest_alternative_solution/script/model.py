import dgl
import torch
import numpy as np
import pytorch_lightning as pl
import torch.nn.functional as F
import dgl.nn.pytorch as graph_nn

from torch import nn
from dgl.nn import Sequential
from typing import Tuple
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score



class RandomForestModel(pl.LightningModule):
    def __init__(
            self,
            input_dimension: int,
            conv_algorithm: str,
            conv_count: int
    ):
        super().__init__()
        self.save_hyperparameters()
        conv_dimensions = [64, 32, 16]
        self.conv_layers = []
        self.rf_layer = RandomForestClassifier()

        for dims in conv_dimensions[:conv_count]:
            self.conv_layers.append(self.__get_conv_layer(
                conv_algorithm,
                input_dimension,
                dims,
            ))
            input_dimension = dims

        self.conv_layers = Sequential(*self.conv_layers)
        self.last_dimension = input_dimension
        self.classify = nn.Linear(input_dimension, 1)
        self.loss_func = nn.BCEWithLogitsLoss()

        self.train_input_list = []
        self.correct_train_label = []
        self.pred_train_label = []

        self.val_input_list = []
        self.correct_val_label = []
        self.pred_val_label = []
        
        self.test_input_list = []
        self.correct_test_label = []
        self.pred_test_label = []
        
        self.train_metrics = self.__get_metric('train')
        self.val_metrics = self.__get_metric('val')
        self.test_metrics = self.__get_metric('test')

        

    def __get_metric(self,stage: str):
        if stage == 'train':
            correct_label = self.correct_train_label
            pred_label = self.pred_train_label
        elif stage == 'test': 
            correct_label = self.correct_test_label
            pred_label = self.pred_test_label
        else:
            correct_label = self.correct_val_label
            pred_label = self.pred_val_label
        if len(correct_label) == 0 or len(pred_label) == 0:
            return {
                f'{stage}_accuracy': 0,
                f'{stage}_f1': 0,
            }
        
        return {
            f'{stage}_accuracy': accuracy_score(pred_label,correct_label),
            f'{stage}_f1': f1_score(pred_label,correct_label),
        }
    def __get_conv_layer(
            self,
            conv_algorithm: str,
            input_dimension: int,
            output_dimension: int
    ) -> nn.Module:
        support_algorithm = {
            "SAGEConv": graph_nn.SAGEConv(
                input_dimension,
                output_dimension,
                activation=F.relu,
                aggregator_type='mean',
                norm=F.normalize
            ),
            "GraphConv": graph_nn.GraphConv(
                input_dimension,
                output_dimension,
                activation=F.relu
            ),
            "GATConv": graph_nn.GATConv(
                input_dimension,
                output_dimension,
                activation=F.relu,
                num_heads=1
            )
        }
        conv_algorithm = conv_algorithm if conv_algorithm in support_algorithm.keys() else "GraphConv"
        return support_algorithm[conv_algorithm]

    def forward(self, g: dgl.DGLGraph, label: int) -> torch.Tensor:
        with g.local_scope():
            h = g.ndata['features']
            h = self.conv_layers(g, h)
            g.ndata['h'] = h if len(self.conv_layers) > 0 else h[0]
            hg = dgl.mean_nodes(g, 'h').detach().numpy()
            return hg

    def training_step(self, batch: Tuple[dgl.DGLGraph, torch.Tensor]) -> torch.Tensor:
        bg, label = batch
        hg = self.forward(bg, label)
        self.train_input_list.append(hg)
        self.correct_train_label.append(label)
        print(len(self.train_input_list), len(self.correct_train_label))
        self.train_metrics = self.__get_metric('train')
        self.log('train_accuracy', self.train_metrics["train_accuracy"], on_step=False, on_epoch=True)
    
    def on_train_end(self) -> None:
        self.rf_layer.fit(self.train_input_list, self.correct_train_label)
    
    def validation_step(self, batch: Tuple[dgl.DGLGraph, torch.Tensor], batch_idx: int):
        bg, label = batch
        prediction = self.forward(bg, label)
        self.correct_train_label.append(label)
        self.pred_train_label.append(prediction)
        self.train_metrics = self.__get_metric('val')
        self.log('val_accuracy', self.train_metrics["val_accuracy"], on_step=False, on_epoch=True)

    
    def test_step(self, batch: Tuple[dgl.DGLGraph, torch.Tensor], batch_idx: int):
        bg, label = batch
        prediction = self.forward(bg, label)
        self.correct_train_label.append(label)
        self.pred_train_label.append(prediction)
        self.train_metrics = self.__get_metric('test')
        self.log('test_accuracy', self.train_metrics["test_accuracy"], on_step=False, on_epoch=True)

    def configure_optimizers(self) -> torch.optim.Adam:
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
        return optimizer
